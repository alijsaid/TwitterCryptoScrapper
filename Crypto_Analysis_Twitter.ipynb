{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crypto_Analysis_Twitter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "Siv5R0m9odCD",
        "outputId": "e5987dd4-7b60-48f9-ff52-f58feb08ede4"
      },
      "source": [
        "# Installing libraries\n",
        "%pip install langdetect \n",
        "%pip install pysentiment2\n",
        "%pip install python-binance\n",
        "\n",
        "# Importing all libraries to be used in the code\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "from langdetect import detect\n",
        "from csv import writer\n",
        "import numpy as np\n",
        "from urllib.request import urlopen, Request\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pysentiment2 as ps\n",
        "from binance import Client\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "sentiment_scores = [] # Initialising the sentiment_scores list which will hold the positive sentiment scores(Percentage of eligible tweets with positive sentiments)\n",
        "price_l = [] # List holds the average price of the currency over the time\n",
        "negative_sentiment_scores = [] # This list holds the percentage of tweets with negative sentiments over time\n",
        "limit = 50 # This is the number of tweets to scrape in each iteration\n",
        "token = str(input('Coin name to look with on twitter: ')) # This means the name of the currenct like BTC,ETH,LTC to be looked out for on Twitter\n",
        "currency = str(input('Currency name: ')) # Name of the currency to be looked out for on Binance like BTCUSDT,ETHUSDT etc.\n",
        "BEARER_TOKEN=\"AAAAAAAAAAAAAAAAAAAAAHH9UAEAAAAA5sA0o6M6OjrRNJ0pNpHKypL%2B%2Bm8%3D3KAHM2kj6PEG0QCNrzMQnacky5IcFHzJYoLhyF2cPAWypKmTbZ\" # Twitter api bearer token\n",
        "in_position = False\n",
        "client = Client('HysmriB8kLQnMzVqRTjnTpCAFZOrJLx4pxT4Ch3a852bECoNgXtmWkGtxubtSbZK','4juSFo7kh4Kcb0DwP2ds5fAh5ilyGVYUaBnXfCGCoale4ns1tCxtBffFOgIM36g0') # Creating the object for binance class to scrape then prices\n",
        "# This function creates the header with bearer token, header helps while sending a request for data to twitter server\n",
        "def create_headers(bearer_token):\n",
        "        headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
        "        return headers\n",
        "\n",
        "# Getting stream rules and putting them into a json\n",
        "def get_rules(headers, bearer_token):\n",
        "    # Sending a request GET command to server to get all rules and if we dont face any exception then put the rules into a json format\n",
        "    response = requests.get(\n",
        "        \"https://api.twitter.com/2/tweets/search/stream/rules\", headers=headers\n",
        "    )\n",
        "    # In case of exception letting the user know\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(\n",
        "            \"Cannot get rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
        "        )\n",
        "    print(json.dumps(response.json()))\n",
        "    return response.json()\n",
        "\n",
        "# Deleting the default rules as we want to reset them to be able to scrape tweets.\n",
        "def delete_all_rules(headers, bearer_token, rules):\n",
        "    if rules is None or \"data\" not in rules:\n",
        "        return None\n",
        "\n",
        "    ids = list(map(lambda rule: rule[\"id\"], rules[\"data\"]))\n",
        "    payload = {\"delete\": {\"ids\": ids}}\n",
        "    response = requests.post(\n",
        "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
        "        headers=headers,\n",
        "        json=payload\n",
        "    )\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(\n",
        "            \"Cannot delete rules (HTTP {}): {}\".format(\n",
        "                response.status_code, response.text\n",
        "            )\n",
        "        )\n",
        "    print(json.dumps(response.json()))\n",
        "\n",
        "# This function sets the rules for scraping the tweets\n",
        "def set_rules(headers, delete, bearer_token):\n",
        "    # You can adjust the rules if needed\n",
        "    global token # Getting the token name given in user input\n",
        "    sample_rules = [\n",
        "        {\"value\": f\"#{token}\", \"tag\": token},\n",
        "    ]\n",
        "    payload = {\"add\": sample_rules}\n",
        "    # Putting the rules into the twitter stream with help of POST command\n",
        "    response = requests.post(\n",
        "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
        "        headers=headers,\n",
        "        json=payload,\n",
        "    )\n",
        "    # If we get a exception then letting the user know\n",
        "    if response.status_code != 201:\n",
        "        raise Exception(\n",
        "            \"Cannot add rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
        "        )\n",
        "    print(json.dumps(response.json()))\n",
        "\n",
        "\n",
        "def get_stream(headers, set, bearer_token):\n",
        "    # This function scrapes the tweets from the api contionously till limit is reached\n",
        "    # The function first gets all tweets from the api then we iterate through the tweets and do a sentiment analysis on it then placing all variables into appropriate list/dictionary\n",
        "    global sentiment_t,fg_index_d,limit\n",
        "    response = requests.get(\n",
        "        \"https://api.twitter.com/2/tweets/search/stream\", headers=headers, stream=True,\n",
        "    )\n",
        "    print(response.status_code)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(\n",
        "            \"Cannot get stream (HTTP {}): {}\".format(\n",
        "                response.status_code, response.text\n",
        "            )\n",
        "        )\n",
        "    current_ind = 0\n",
        "    for response_line in response.iter_lines(): # Iterating through the response from twitter api\n",
        "        if response_line: \n",
        "            if current_ind == limit: # Checking if we havent hit the limit of number of tweets to look for per iteration\n",
        "              break\n",
        "            current_ind += 1\n",
        "            json_response = json.loads(response_line) # Unloading the json response\n",
        "            tweet = json_response['data']['text'] # Extracting tweet from json response\n",
        "            tweet = tweet.replace(':','') # Cleaning the tweet\n",
        "            try:\n",
        "                if detect(tweet) == 'en': # If tweets language is english\n",
        "                    print('')\n",
        "                    print(tweet)\n",
        "                    print('')\n",
        "                    try: \n",
        "                        tokens = lm.tokenize(tweet) # Applying sentiment analysis on the tweet\n",
        "                        score = lm.get_score(tokens)\n",
        "                        if score['Positive']>score['Negative']: # If tweets positive score exceeds the negative then adding +1 into positive sentiment tweets and similar for negative sentiment tweets\n",
        "                            sentiment_t['Positive']+=1\n",
        "                        elif score['Negative']>score['Positive']:\n",
        "                            sentiment_t['Negative']+=1\n",
        "                    except:\n",
        "                        pass\n",
        "            except Exception as e:\n",
        "              print(e)\n",
        "              pass\n",
        "def main():\n",
        "    # Here we just call the above functions in right order\n",
        "    # This function is like a driver code\n",
        "    try:\n",
        "        bearer_token = BEARER_TOKEN\n",
        "        headers = create_headers(bearer_token)\n",
        "        rules = get_rules(headers, bearer_token)\n",
        "        delete = delete_all_rules(headers, bearer_token, rules)\n",
        "        set = set_rules(headers, delete, bearer_token)\n",
        "        get_stream(headers, set, bearer_token)\n",
        "    except Exception as ef:\n",
        "        print(ef)\n",
        "        print('Done')\n",
        "\n",
        "for x in range(3): # Scraping the tweets and processing them n time given in range\n",
        "    lm = ps.LM() # Initialising the sentiment analysis object\n",
        "    sentiment_t = {'Positive':0,'Negative':0} # Initialising the sentiments dictionary to be used\n",
        "    main() # Calling the main function to start the process\n",
        "    print(sentiment_t) # After limit is reached printing the sentiments list and how much positive score was\n",
        "    print(f'Tweet Sentiment : {max(sentiment_t, key=sentiment_t.get)}')\n",
        "\n",
        "    # Calculating the negative sentiments percentage,positive sentiments percentage\n",
        "    negative_sentiment_score = (sentiment_t['Negative']/sum(sentiment_t.values()))*100\n",
        "    tweet_score=(sentiment_t['Positive']/sum(sentiment_t.values()))*100\n",
        "    print(f'Tweets Positive Sentiment Score : {tweet_score}')\n",
        "    avg_price = client.get_avg_price(symbol=currency) # Fetching price from binance\n",
        "    sentiment_scores.append(tweet_score) # Adding positive sentiment percentage,negative sentiment percentage and avg price at the moment into the appropriate list\n",
        "    price_l.append(avg_price)\n",
        "    negative_sentiment_scores.append(negative_sentiment_score)\n",
        "    print('########### 10 SECONDS BREAK ##############')\n",
        "    time.sleep(10)\n",
        "\n",
        "prices = []\n",
        "for x in price_l:\n",
        "  prices.append(float(x['price'])) # Extracting prices fetched over time\n",
        "corr, _ = pearsonr(sentiment_scores, prices) # Calculating pearson correlation between positive sentiments percentage and prices over time\n",
        "print('Correlation: %.3f' % corr) # Printing the correlation\n",
        "figure, axis = plt.subplots(3, 1) # Creating 3 plots in 1 columns\n",
        "axis[0].plot(sentiment_scores) # Plotting the positive sentiments graph\n",
        "axis[0].set_title(\"Positive Sentiments\")\n",
        "\n",
        "axis[1].plot(prices) # Plotting the price graph\n",
        "axis[1].set_title(\"Price\")\n",
        "\n",
        "axis[2].plot(negative_sentiment_scores) # Plotting the negative sentiments graph\n",
        "axis[2].set_title(\"Negative Sentiments\")\n",
        "\n",
        "figure.tight_layout()\n",
        "plt.show() # Showing all graphs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Requirement already satisfied: pysentiment2 in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pysentiment2) (1.3.5)\n",
            "Requirement already satisfied: nltk>=2.0 in /usr/local/lib/python3.7/dist-packages (from pysentiment2) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=2.0->pysentiment2) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pysentiment2) (1.21.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pysentiment2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pysentiment2) (2.8.2)\n",
            "Requirement already satisfied: python-binance in /usr/local/lib/python3.7/dist-packages (1.0.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from python-binance) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from python-binance) (2.23.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.7/dist-packages (from python-binance) (10.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-binance) (1.15.0)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.7/dist-packages (from python-binance) (1.1.1)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from python-binance) (5.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance) (2.0.12)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance) (3.10.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance) (6.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->python-binance) (2.10)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser->python-binance) (2018.9)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser->python-binance) (1.5.1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,<2022.3.15 in /usr/local/lib/python3.7/dist-packages (from dateparser->python-binance) (2019.12.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser->python-binance) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->python-binance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->python-binance) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->python-binance) (3.0.4)\n",
            "Coin name to look with on twitter: BTC\n",
            "Currency name: BTCUSDT\n",
            "Cannot get rules (HTTP 401): {\"title\":\"Unauthorized\",\"detail\":\"Unauthorized\",\"type\":\"about:blank\",\"status\":401}\n",
            "Done\n",
            "{'Positive': 0, 'Negative': 0}\n",
            "Tweet Sentiment : Positive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d12b19842ff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# Calculating the negative sentiments percentage,positive sentiments percentage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mnegative_sentiment_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentiment_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0mtweet_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Tweets Positive Sentiment Score : {tweet_score}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    }
  ]
}